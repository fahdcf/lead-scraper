# ğŸš€ Morocco Web Scraper - Clean & Simple

A streamlined Node.js CLI application that extracts contact information (emails and phone numbers) from business websites and LinkedIn profiles across Morocco using AI-powered query generation.

## âœ¨ Features

- **AI-Powered Query Generation**: Uses Gemini AI to generate context-aware search queries
- **Multi-Source Search**: Google Search for business websites + LinkedIn for professional profiles
- **Enhanced Deduplication**: Intelligent removal of duplicate emails and phone numbers
- **Content Validation**: Smart filtering to ensure relevant results
- **Multiple Export Formats**: CSV, Excel, and Text file support
- **Interruption Handling**: Saves partial results if process is interrupted

## ğŸ—ï¸ Project Structure

```
bot-scraper/
â”œâ”€â”€ scraper.js                    # Main CLI application
â”œâ”€â”€ config.js                     # Configuration & API keys
â”œâ”€â”€ manage_api_keys.js            # Interactive API key management
â”œâ”€â”€ helpers/
â”‚   â”œâ”€â”€ geminiAI.js              # AI query generation
â”‚   â”œâ”€â”€ googleSearch.js          # Google Custom Search API
â”‚   â”œâ”€â”€ multiSourceSearch.js     # Multi-source orchestration
â”‚   â”œâ”€â”€ contentValidator.js      # Content filtering
â”‚   â”œâ”€â”€ exportToCsv.js          # Data export (CSV/Excel/TXT)
â”‚   â”œâ”€â”€ extractEmails.js        # Email extraction
â”‚   â”œâ”€â”€ extractPhones.js        # Phone extraction
â”‚   â””â”€â”€ fetchPage.js            # HTTP requests
```

## ğŸš€ Quick Start

1. **Install dependencies**:
   ```bash
   npm install
   ```

2. **Configure API keys**:
   ```bash
   npm run keys
   ```
   Or manually edit `env.config` file.

3. **Run the scraper**:
```bash
npm start
```

## ğŸ“Š Data Sources

### Google Search (Business Websites)
- Extracts emails and phone numbers from business websites
- Uses AI-generated queries for better targeting
- Content validation ensures relevant results
- Enhanced deduplication removes duplicates

### LinkedIn (Professional Profiles)
- Finds professional profiles and company pages
- Exports to Excel format with clickable links
- Smart deduplication based on name and URL
- Preserves profile completeness information

## ğŸ”§ Configuration

### Required API Keys
- **Google Custom Search API**: For web search functionality
- **Gemini AI API**: For intelligent query generation

### Environment Variables (`env.config`)
```
GOOGLE_API_KEY_1=your_google_api_key_1
GOOGLE_API_KEY_2=your_google_api_key_2
GEMINI_API_KEY=your_gemini_api_key
```

## ğŸ“ˆ Enhanced Deduplication

The scraper now includes intelligent deduplication:

### Email Deduplication
- Normalizes email addresses (lowercase, removes +tags)
- Filters out disposable email domains
- Removes exact duplicates

### Phone Number Deduplication
- Standardizes Moroccan phone numbers to +212 format
- Handles various input formats (06, 07, 212, etc.)
- Removes duplicate numbers

### LinkedIn Profile Deduplication
- Removes duplicate URLs
- Keeps profiles with more complete information
- Handles name variations

## ğŸ“ Output Files

### Google Search Results
- **Format**: Text file (.txt)
- **Content**: Emails and phone numbers
- **Naming**: `{niche}_results.txt`

### LinkedIn Results
- **Format**: Excel file (.xlsx)
- **Content**: Profile information with clickable links
- **Naming**: `{niche}_linkedin_results.xlsx`

## ğŸ¯ Usage Examples

```bash
# Scrape website developers in Casablanca
npm start
# Enter: "website developers in Casablanca"
# Select: Google Search
# Select: Both emails and phones

# Scrape LinkedIn profiles for dentists
npm start
# Enter: "dentists in Morocco"
# Select: LinkedIn
```

## ğŸ” Content Validation

The scraper uses intelligent content validation:
- **Keyword Matching**: Ensures content matches target niche
- **Business Indicators**: Identifies business-related content
- **Platform Filtering**: Excludes social media and support pages
- **Contact Validation**: Verifies extracted contact information

## ğŸ› ï¸ Development

### Scripts
- `npm start` - Run the main scraper
- `npm run keys` - Manage API keys
- `npm run dev` - Run with file watching

### Adding New Features
1. The project is modular - add new helpers in the `helpers/` directory
2. Update `scraper.js` to integrate new functionality
3. Test with `npm start`

## ğŸ“ Notes

- **Rate Limiting**: Built-in delays respect server resources
- **Error Handling**: Graceful failure recovery
- **Memory Management**: Efficient processing for large datasets
- **Security**: Only scrapes publicly available information

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details.

---

**Note**: This is a cleaned version of the original project with advanced features removed and enhanced deduplication added. The scraper focuses on simplicity, reliability, and data quality. 